{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f9948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to write an essay on RAG. Let me start by recalling what RAG is. I think it stands for Retrieval-Augmented Generation. I remember it's a method that combines information retrieval with language generation. So, first, I should define RAG clearly.\n",
      "\n",
      "I should explain how traditional language models work versus how RAG improves upon them. Maybe mention that traditional models rely solely on their training data, which can be outdated. RAG adds a retrieval component to fetch the most relevant information from a database or the web.\n",
      "\n",
      "Next, I should talk about the components of RAG: retrieval and generation. The retrieval part uses a system like a search engine to find documents related to the query. Then the generation model uses that information to create a response. It's important to highlight the synergy between these two parts.\n",
      "\n",
      "I need to discuss advantages of RAG. One is up-to-date information because it can access current data. Another is the ability to provide accurate and contextually relevant answers by leveraging external knowledge. Maybe mention use cases like customer support, research, or education where RAG can be beneficial.\n",
      "\n",
      "I should also address limitations. For example, the quality depends on the retrieval system; if the search isn't good, the generated answer might be off. Also, there could be issues with the integration of retrieval and generation, like handling conflicting information from the retrieved documents.\n",
      "\n",
      "Are there any specific examples of systems using RAG? I think IBM's Watson or some other AI assistants might use similar techniques. Maybe mention that RAG is used in various AI applications to enhance their capabilities.\n",
      "\n",
      "I need to structure the essay with an introduction, sections on traditional models, the components of RAG, its advantages, limitations, and a conclusion. Make sure to use clear examples and explain technical terms in simple language.\n",
      "\n",
      "Wait, I should also check if there are any recent advancements in RAG technology. Maybe there are newer versions or hybrid models that combine RAG with other techniques. But since the user didn't specify the scope, sticking to the basics might be better.\n",
      "\n",
      "Let me verify some key points. RAG was introduced to overcome the limitations of static training data. It allows models to access external sources during inference. The retrieval step is crucial as it fetches the most relevant documents, which are then used by the generator to create a response. The generator is typically a language model like T5 or BERT.\n",
      "\n",
      "I should also mention that RAG can be implemented using different architectures, like using a dense vector representation for documents and queries to find similar content. Techniques like FAISS for efficient retrieval might be relevant here.\n",
      "\n",
      "What about the training process? Does RAG require training the retrieval model and the generator separately or together? I think in some implementations, they are trained end-to-end, which allows the system to optimize both components for the specific task.\n",
      "\n",
      "I need to make sure that the essay flows logically, each section building on the previous one. Start with the problem traditional models have with outdated information, introduce RAG as a solution, explain how it works, its benefits, challenges, and conclude with its importance in advancing AI capabilities.\n",
      "\n",
      "Also, maybe touch on how RAG contributes to more transparent AI systems since the retrieved documents can be reviewed to verify the sources of information. This can increase trust in the model's responses.\n",
      "\n",
      "I should avoid getting too technical, but still be precise. Define acronyms when first mentioned. Check for any common misconceptions about RAG, like thinking it's just a search engine, but emphasize the combination with generation.\n",
      "\n",
      "Alright, putting it all together now. Start drafting each section with these points in mind, ensuring clarity and coherence.\n",
      "</think>\n",
      "\n",
      "**Title: Retrieval-Augmented Generation (RAG): Bridging the Gap Between Static Knowledge and Dynamic Information**\n",
      "\n",
      "**Introduction**  \n",
      "In the rapidly evolving field of artificial intelligence, language models have revolutionized how we interact with technology. However, traditional models like GPT-3 or BERT, trained on historical data, often struggle with outdated information and lack the ability to access real-time data during inference. This limitation spurred the development of Retrieval-Augmented Generation (RAG), a hybrid approach that integrates information retrieval and language generation. By combining the strengths of search engines and language models, RAG addresses the shortcomings of static training data, offering more accurate, up-to-date, and contextually relevant responses.\n",
      "\n",
      "**Traditional Language Models: A Static Foundation**  \n",
      "Conventional language models are trained on vast datasets containing historical text from books, articles, and the internet. While these models excel at pattern recognition and generating coherent text, their knowledge is confined to the data they were trained on—data that becomes outdated as new information emerges. For instance, a model trained in 2023 might lack knowledge about events occurring in 2024. This rigidity limits their applicability in dynamic domains like news, scientific research, or customer support, where real-time accuracy is paramount.\n",
      "\n",
      "**The RAG Framework: Retrieval Meets Generation**  \n",
      "RAG introduces a two-stage process to augment the capabilities of language models:  \n",
      "1. **Retrieval**: A search engine or database (e.g., Elasticsearch, FAISS) identifies the most relevant documents related to the user’s query. These documents act as external knowledge sources, ensuring the model can access up-to-date or domain-specific information.  \n",
      "2. **Generation**: A language model synthesizes the retrieved information to craft a response. This generator, often a fine-tuned transformer model like T5 or BERT, leverages the retrieved documents to produce contextually accurate and informative answers.\n",
      "\n",
      "For example, if asked, “What is the current population of Tokyo?” RAG might first query a real-time database or recent census data, then generate a precise answer based on the retrieved figures.\n",
      "\n",
      "**Advantages of RAG**  \n",
      "1. **Dynamic Knowledge**: RAG models can incorporate the latest data, making them ideal for time-sensitive queries.  \n",
      "2. **Improved Accuracy**: By cross-referencing multiple documents, RAG reduces hallucinations—false information generated by models relying solely on training data.  \n",
      "3. **Contextual Relevance**: The retrieval step ensures responses are grounded in relevant sources, enhancing trust and transparency.  \n",
      "4. **Versatility**: RAG supports diverse applications, from answering customer FAQs using a company’s internal knowledge base to aiding researchers by synthesizing recent scientific studies.\n",
      "\n",
      "**Challenges and Limitations**  \n",
      "Despite its benefits, RAG faces challenges:  \n",
      "- **Dependency on Retrieval Quality**: Suboptimal search algorithms may retrieve irrelevant or outdated documents, compromising the response.  \n",
      "- **Integration Complexity**: Balancing retrieval and generation requires careful engineering to avoid conflicts in retrieved information.  \n",
      "- **Computational Overhead**: The dual-stage process increases latency compared to pure generative models.  \n",
      "\n",
      "For instance, if a retrieval system misidentifies a document, the generator might propagate inaccuracies. To mitigate this, RAG systems often employ redundancy or voting mechanisms to prioritize the most credible sources.\n",
      "\n",
      "**Real-World Applications and Future Directions**  \n",
      "RAG has been adopted in AI assistants like IBM’s Watson and chatbots for customer service, where access to updated databases is critical. In academia, it aids researchers by summarizing recent literature, while in education, it personalizes learning by retrieving tailored resources.  \n",
      "\n",
      "Looking ahead, advancements in hybrid models—such as integrating RAG with reinforcement learning—could further optimize retrieval strategies. Techniques like multi-vector retrieval, where multiple document representations are queried, may enhance efficiency. Additionally, open-source frameworks like Haystack and LangChain are democratizing RAG implementation, enabling developers to build robust systems tailored to specific domains.\n",
      "\n",
      "**Conclusion**  \n",
      "Retrieval-Augmented Generation represents a significant leap in AI’s ability to blend static training knowledge with dynamic external data. By addressing the limitations of traditional models, RAG not only improves accuracy and relevance but also fosters transparency in AI decision-making. As retrieval algorithms and generative models continue to evolve, RAG stands as a testament to the power of hybrid systems, paving the way for smarter, more adaptable AI across industries. Its success underscores a critical lesson: in an era of rapid information growth, the future lies in systems that learn not just from the past, but from the present as well."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "model=init_chat_model(\"groq:qwen/qwen3-32b\")\n",
    "\n",
    "for chunk in model.stream(\"Write me an essay on RAG\"):\n",
    "    if chunk.content:\n",
    "        print(chunk.content,end=\"\",flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfe2fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location:str)->str:\n",
    "    \"\"\" Get the weather at a location \"\"\"\n",
    "    return f\"It's sunny in {location}\"\n",
    "\n",
    "model_with_tools=model.bind_tools([get_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bd0b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'reasoning_content': 'Okay, the user is asking for the weather in Bangalore. I need to use the get_weather function. The function requires a location parameter. Bangalore is the location here, so I should call the function with \"Bangalore\" as the argument. Let me make sure there are no typos. Everything looks good. I\\'ll format the tool call correctly within the XML tags.\\n', 'tool_calls': [{'id': '87tafaz59', 'function': {'arguments': '{\"location\":\"Bangalore\"}', 'name': 'get_weather'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 151, 'total_tokens': 251, 'completion_time': 0.178191805, 'completion_tokens_details': {'reasoning_tokens': 75}, 'prompt_time': 0.007334546, 'prompt_tokens_details': None, 'queue_time': 0.047297794, 'total_time': 0.185526351}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c32a1-73ca-7510-b871-cc1700dd49d3-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Bangalore'}, 'id': '87tafaz59', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 151, 'output_tokens': 100, 'total_tokens': 251, 'output_token_details': {'reasoning': 75}}\n"
     ]
    }
   ],
   "source": [
    "response=model_with_tools.invoke(\"Whats the weather in Bangalore\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4486fe3",
   "metadata": {},
   "source": [
    "### Tool execution loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cc13c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Bangalore, India is currently sunny ☀️. Let me know if you'd like to check another location!\n"
     ]
    }
   ],
   "source": [
    "messages=[{\"role\": \"user\",\"content\": \"What's the weather in Bangalore?\"}]\n",
    "ai_msg=model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    tool_result=get_weather.invoke(tool_call)\n",
    "    messages.append(tool_result)\n",
    "\n",
    "final_response=model_with_tools.invoke(messages)\n",
    "print(final_response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
